{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Notebook Dir: /home/mangabat/projects/portofolio/backend/aiml_models/agent_teams/agent_tailored_cover_letter/notebook\n",
      "Project Root (agent_tailored_cover_letter): /home/mangabat/projects/portofolio/backend/aiml_models/agent_teams/agent_tailored_cover_letter\n",
      "Adding SRC_DIR to sys.path: /home/mangabat/projects/portofolio/backend/aiml_models/agent_teams/agent_tailored_cover_letter/src\n"
     ]
    }
   ],
   "source": [
    "# backend/aiml_models/agent_teams/agent_tailored_cover_letter/src/notebook/playground.ipynb\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Locate the \"src\" dynamically from notebook location\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(NOTEBOOK_DIR, \"..\"))\n",
    "\n",
    "SRC_DIR = os.path.join(PROJECT_ROOT, \"src\")\n",
    "\n",
    "# Debug prints to check\n",
    "print(f\"Current Notebook Dir: {NOTEBOOK_DIR}\")\n",
    "print(f\"Project Root (agent_tailored_cover_letter): {PROJECT_ROOT}\")\n",
    "print(f\"Adding SRC_DIR to sys.path: {SRC_DIR}\")\n",
    "\n",
    "sys.path.append(SRC_DIR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "from typing import List, Literal, Dict\n",
    "\n",
    "class CorrectionsClient:\n",
    "    def __init__(self) -> None:\n",
    "        self.base_url = \"http://localhost:8010/corrections\"\n",
    "\n",
    "    def fetch_corrections(self, correction_type: Literal[\"word\", \"sentence\", \"skill\"]) -> List[Dict[str, str]]:\n",
    "        response = httpx.get(self.base_url, params={\"correction_type\": correction_type})\n",
    "        response.raise_for_status()\n",
    "        return response.json()  # Ensure it returns a list of dictionaries\n",
    "    \n",
    "skills = CorrectionsClient().fetch_corrections(\"skill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"\"\"\n",
    "Data Scientist til Fraud Detection & AI Solutions\n",
    "Kan du dykke dybt i data? Har du styr på Machine Learning-modeller, SQL og Python? Og vil du arbejde med landets mest interessante datagrundlag? Så er du den Data Scientist, vi søger til afdelingen Fraud Detection & AI Solutions.\n",
    "Vil du være med til at fremtidssikre velfærdssamfundet med teknologier som ML, NLP og Computer Vision?\n",
    "I Digital Solutions får vi velfærden til at fungere. Vi spiller en afgørende rolle i digitaliseringen af det danske samfund, fordi vi står bag de systemer, der får to ud af tre velfærdskroner ud til danskerne. \n",
    "Her er vi lige nu på udkig efter en Data Scientist til afdelingen Fraud Detection & AI Solutions, hvor vi bl.a. sikrer en koordineret indsats i forhold til kontrol af fejludbetalinger og snyd med offentlige ydelser. \n",
    "Derudover spiller vi en vigtig rolle i arbejdet med effektivisering af forretningens processer ved brug af teknologier som Machine Learning, NLP, Computer vision og lignende teknologier. Siden sidste år har vi kortlagt et (kæmpe)stort NLP-potentiale på tværs af ATP, og nu arbejder vi på at udvikle og implementere løsningerne, så vi sikrer en effektiv udbetaling.\n",
    "I jobbet som Data Scientist er det mere konkret dig, der: \n",
    "Forstår forretningens behov på tæt hold.\n",
    "For at udvikle de bedste løsninger er det vigtigt at forstå forretningens behov. Derfor kommer du til at arbejde tæt sammen med forskellige teams for at afdække deres behov og omsætte dem til datadrevne løsninger.\n",
    "Udvikler avancerede modeller i Python\n",
    "Du er med til at udvikle statistiske modeller i Python, der er baseret på Machine Learning ved brug af både træningsdata og unsupervised metoder.\n",
    "Vedligeholder og monitorerer vores modeller\n",
    "For at sikre, at vores modeller fungerer optimalt, bliver du ansvarlig for løbende monitorering og vedligeholdelse. Her holder bl.a. øje med, hvorvidt modellerne opfører sig som forventet og tilpasser dem efter behov.\n",
    "Er med fra udvikling til produktion\n",
    "Vi arbejder med best practices fra softwareudvikling for at gøre overgangen fra udvikling til produktion så gnidningsfri som muligt. Du er derfor med til at sikre, at vores løsninger bringes sikkert fra udvikling til produktion i vores scrum-setup.\n",
    "Udvikler og implementerer NLP-løsninger\n",
    "Sidst, men ikke mindst, kommer du til at spille en central rolle i udviklingen af NLP-løsninger og sørger for, at de bliver produktionssat og taget i brug af vores interne kunder.\n",
    "Har du styr på SQL og Python?\n",
    "Der kan være flere veje til rollen som Data Scientist, men vi forestiller os, at du har en relevant kandidatgrad inden for matematik, statistik, fysik, computer science, ingeniørvidenskab eller lignende. Hvis du har et par års erfaring, er det en fordel.\n",
    "Derudover er du:\n",
    "erfaren når det kommer til dataanalyse og udvikling af Machine Learning-modeller\n",
    "en haj til Python, SQL og lignende (en fordel, ikke et krav)\n",
    "med til at skabe resultater i samarbejde med andre\n",
    "god til at finde enkle løsninger på komplekse udfordringer.\n",
    "Vil du være en del af et unikt it-fagligt fællesskab?\n",
    "I Fraud Detection & AI er vi en del af enheden Data i Digital Solutions. Vi brænder for data og de muligheder, data kan skabe. Som landets største udbetalingshus administrerer ATP to ud af tre velfærdskroner i Danmark. \n",
    "Vi arbejder med et unikt datagrundlag, som giver os særlige muligheder – både for at lave dybdegående analyser og for at udvikle datadrevne løsninger.\n",
    "Du bliver en del af en afdeling med mere end 40 dygtige kolleger, der arbejder som Data Scientists, Software Developers, Data Analysts og forretningsansvarlige. Du kommer især til at arbejde tæt sammen med afdelingens dygtige tekniske specialister, som arbejder med Data Science og softwareudvikling i full-stack-løsninger. \n",
    "Vi arbejder i et fagligt stærkt miljø, hvor vi deler viden og hjælper hinanden med at udvikle os – både teknisk og personligt.\n",
    "I ATP er barren sat højt, både når det gælder ambitioner og trivsel. Vi tror på et arbejdsliv i balance. Det kræver fleksibilitet med plads til den enkelte - og det har vi.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x7f38f664dba0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f38f6653a60> root_client=<openai.OpenAI object at 0x7f38f664ce20> root_async_client=<openai.AsyncOpenAI object at 0x7f38f64ba5f0> model_name='gpt-4o-2024-11-20' model_kwargs={} openai_api_key=SecretStr('**********') seed=66\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from typing import List\n",
    "from langchain.schema import BaseMessage\n",
    "\n",
    "class LLMClient:\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "        This client wraps Langchain's ChatOllama to invoke local LLMs via Ollama.\n",
    "\n",
    "    Capabilities:\n",
    "        - Accepts system + human messages using Langchain schema.\n",
    "        - Uses Langchain's Ollama integration directly — no manual API calls.\n",
    "        - Returns the final response as plain text (ready for parsing).\n",
    "\n",
    "    Reasoning:\n",
    "        - This keeps you aligned with Langchain’s native event flow.\n",
    "        - You benefit from any future Langchain enhancements to `ChatOllama`.\n",
    "        - You avoid any API version mismatches between you and Ollama.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: str ) -> None:\n",
    "        self.llm = ChatOllama(\n",
    "            model=model,\n",
    "            format=\"json\"\n",
    "            )\n",
    "\n",
    "model = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "# class_model = LLMClient(model=\"deepseek-r1:1.5b\")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_model = ChatOpenAI(\n",
    "    api_key=\"sk-proj-eVPJa885ae9aQ6dLTOQ7T3BlbkFJ9RElN72FpTcwNWI6r7uO\",\n",
    "    seed = 66,\n",
    "    model=\"gpt-4o-2024-11-20\"\n",
    ")\n",
    "\n",
    "print((llm_model))\n",
    "# print(type(class_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backend/aiml_models/agent_teams/agent_tailored_cover_letter/src/core/data_models/analysis_result_model.py\n",
    "\n",
    "from typing import Dict\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class JobAnalysisResult(BaseModel):\n",
    "    company_name: str = Field(description=\"Identified company name\")\n",
    "    job_title: str = Field(description=\"Identified job title\")\n",
    "    analysis_output: str = Field(description=\"Analysis of the vacancy\")\n",
    "    employees_skills_requirement: dict = Field(description=\"identified skills and technical experience required for the job vacancy\")\n",
    "    matching_skills: dict = Field(description=\"matching skills in the job vacancy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['my_skills'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"company_name\": {\"description\": \"Identified company name\", \"title\": \"Company Name\", \"type\": \"string\"}, \"job_title\": {\"description\": \"Identified job title\", \"title\": \"Job Title\", \"type\": \"string\"}, \"analysis_output\": {\"description\": \"Analysis of the vacancy\", \"title\": \"Analysis Output\", \"type\": \"string\"}, \"employees_skills_requirement\": {\"description\": \"identified skills and technical experience required for the job vacancy\", \"title\": \"Employees Skills Requirement\", \"type\": \"object\"}, \"matching_skills\": {\"description\": \"matching skills in the job vacancy\", \"title\": \"Matching Skills\", \"type\": \"object\"}}, \"required\": [\"company_name\", \"job_title\", \"analysis_output\", \"employees_skills_requirement\", \"matching_skills\"]}\\n```'}, template=\"\\n        You are an AI assistant specializing in HR job analysis.\\n        Your task is to analyze a given job vacancy and match it with a candidate's skills.\\n        - Identified relevant skills from the job description.\\n        - Match the required skills with the candidate’s skills.\\n        - Assess the candidate's suitability for the role.\\n        - Identify:\\n            - The company name.\\n            - The job title.\\n            - Required skills and technical experience (stored as a dictionary).\\n            - Matching skills (stored as a dictionary).\\n        - Write a detailed analysis of the job vacancy and the candidate's skills on a one pager\\n        The candidate's skills are:\\n        {my_skills}\\n\\n        {format_instructions}\\n        \"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_position'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"company_name\": {\"description\": \"Identified company name\", \"title\": \"Company Name\", \"type\": \"string\"}, \"job_title\": {\"description\": \"Identified job title\", \"title\": \"Job Title\", \"type\": \"string\"}, \"analysis_output\": {\"description\": \"Analysis of the vacancy\", \"title\": \"Analysis Output\", \"type\": \"string\"}, \"employees_skills_requirement\": {\"description\": \"identified skills and technical experience required for the job vacancy\", \"title\": \"Employees Skills Requirement\", \"type\": \"object\"}, \"matching_skills\": {\"description\": \"matching skills in the job vacancy\", \"title\": \"Matching Skills\", \"type\": \"object\"}}, \"required\": [\"company_name\", \"job_title\", \"analysis_output\", \"employees_skills_requirement\", \"matching_skills\"]}\\n```'}, template='\\n        Here is a job description that needs analysis:\\n        Job Vacancy: \\n        {job_position}\\n        \\n        {format_instructions}\\n        '), additional_kwargs={})]\n",
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['job_position', 'my_skills'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['my_skills'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"company_name\": {\"description\": \"Identified company name\", \"title\": \"Company Name\", \"type\": \"string\"}, \"job_title\": {\"description\": \"Identified job title\", \"title\": \"Job Title\", \"type\": \"string\"}, \"analysis_output\": {\"description\": \"Analysis of the vacancy\", \"title\": \"Analysis Output\", \"type\": \"string\"}, \"employees_skills_requirement\": {\"description\": \"identified skills and technical experience required for the job vacancy\", \"title\": \"Employees Skills Requirement\", \"type\": \"object\"}, \"matching_skills\": {\"description\": \"matching skills in the job vacancy\", \"title\": \"Matching Skills\", \"type\": \"object\"}}, \"required\": [\"company_name\", \"job_title\", \"analysis_output\", \"employees_skills_requirement\", \"matching_skills\"]}\\n```'}, template=\"\\n        You are an AI assistant specializing in HR job analysis.\\n        Your task is to analyze a given job vacancy and match it with a candidate's skills.\\n        - Identified relevant skills from the job description.\\n        - Match the required skills with the candidate’s skills.\\n        - Assess the candidate's suitability for the role.\\n        - Identify:\\n            - The company name.\\n            - The job title.\\n            - Required skills and technical experience (stored as a dictionary).\\n            - Matching skills (stored as a dictionary).\\n        - Write a detailed analysis of the job vacancy and the candidate's skills on a one pager\\n        The candidate's skills are:\\n        {my_skills}\\n\\n        {format_instructions}\\n        \"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_position'], input_types={}, partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"company_name\": {\"description\": \"Identified company name\", \"title\": \"Company Name\", \"type\": \"string\"}, \"job_title\": {\"description\": \"Identified job title\", \"title\": \"Job Title\", \"type\": \"string\"}, \"analysis_output\": {\"description\": \"Analysis of the vacancy\", \"title\": \"Analysis Output\", \"type\": \"string\"}, \"employees_skills_requirement\": {\"description\": \"identified skills and technical experience required for the job vacancy\", \"title\": \"Employees Skills Requirement\", \"type\": \"object\"}, \"matching_skills\": {\"description\": \"matching skills in the job vacancy\", \"title\": \"Matching Skills\", \"type\": \"object\"}}, \"required\": [\"company_name\", \"job_title\", \"analysis_output\", \"employees_skills_requirement\", \"matching_skills\"]}\\n```'}, template='\\n        Here is a job description that needs analysis:\\n        Job Vacancy: \\n        {job_position}\\n        \\n        {format_instructions}\\n        '), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# backend/aiml_models/agent_teams/agent_tailored_cover_letter/src/core/company_analysis/components/analysis_prompt_builder.py\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "class JobAnalysisResult(BaseModel):\n",
    "    company_name: str = Field(description=\"Identified company name\")\n",
    "    job_title: str = Field(description=\"Identified job title\")\n",
    "    analysis_output: str = Field(description=\"Analysis of the vacancy\")\n",
    "    employees_skills_requirement: dict = Field(description=\"identified skills and technical experience required for the job vacancy\")\n",
    "    matching_skills: dict = Field(description=\"matching skills in the job vacancy\")\n",
    "\n",
    "\n",
    "\n",
    "def build_prompt(jd, s, parser: PydanticOutputParser) -> ChatPromptTemplate:\n",
    "\n",
    "        # System message enforcing JSON output\n",
    "        system_analysis_template_str = \"\"\"\n",
    "        You are an AI assistant specializing in HR job analysis.\n",
    "        Your task is to analyze a given job vacancy and match it with a candidate's skills.\n",
    "        - Identified relevant skills from the job description.\n",
    "        - Match the required skills with the candidate’s skills.\n",
    "        - Assess the candidate's suitability for the role.\n",
    "        - Identify:\n",
    "            - The company name.\n",
    "            - The job title.\n",
    "            - Required skills and technical experience (stored as a dictionary).\n",
    "            - Matching skills (stored as a dictionary).\n",
    "        - Write a detailed analysis of the job vacancy and the candidate's skills on a one pager\n",
    "        The candidate's skills are:\n",
    "        {my_skills}\n",
    "\n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "\n",
    "        SYSTEM_PROMPT = SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                template=system_analysis_template_str,\n",
    "                input_variables=[\"my_skills\"],  # No user input needed\n",
    "                partial_variables={\"format_instructions\": parser.get_format_instructions()}  # Enforce JSON format\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Human input message\n",
    "        human_analysis_template_str = \"\"\"\n",
    "        Here is a job description that needs analysis:\n",
    "        Job Vacancy: \n",
    "        {job_position}\n",
    "        \n",
    "        {format_instructions}\n",
    "        \"\"\"\n",
    "\n",
    "        HUMAN_PROMPT = HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                template=human_analysis_template_str,\n",
    "                input_variables=[\"job_position\"],\n",
    "                partial_variables={\"format_instructions\": parser.get_format_instructions()}  # Enforce JSON format\n",
    "            )\n",
    "        )\n",
    "        # Ensure that messages are formatted BEFORE returning the ChatPromptTemplate\n",
    "        messages = [SYSTEM_PROMPT, HUMAN_PROMPT]\n",
    "        print(messages)\n",
    "        chat_prompt = ChatPromptTemplate(\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        derp = parser.get_format_instructions()\n",
    "\n",
    "        chat_prompt.format_messages(\n",
    "            job_position=jd,\n",
    "            my_skills=s,\n",
    "            format_messages=derp\n",
    "        )\n",
    "\n",
    "        return chat_prompt\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=JobAnalysisResult)\n",
    "\n",
    "\n",
    "prompt = build_prompt(job_description, skills, parser)\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "company_name='ATP' job_title='Data Scientist - Fraud Detection & AI Solutions' analysis_output=\"The job vacancy at ATP for a 'Data Scientist - Fraud Detection & AI Solutions' primarily focuses on leveraging data science techniques, machine learning, and NLP to detect fraud and optimize processes in the welfare system. Key responsibilities include understanding business requirements, developing machine learning models using Python, monitoring and maintaining these models, and developing and implementing NLP solutions. The job also involves a collaborative working environment in an agile (SCRUM) setup. The candidate's skills largely match the role's requirements, especially in Python, SQL, NLP, Machine Learning, and collaborative working styles. However, the role specifies a preferred background in mathematics, statistics, or related fields and familiarity with 'unsupervised methods and computer vision,' which are not explicitly mentioned among the candidate's current skills. Overall, the candidate is a strong fit for the role, with opportunities to align further through experience or training in unsupervised methods and computer vision.\" employees_skills_requirement={'Machine Learning': 'Experienced in data analysis and Machine Learning model development', 'Python': 'Proficiency and coding experience in Python', 'SQL': 'Proficiency in SQL and similar database tools', 'NLP': 'Expertise in developing and implementing NLP solutions', 'Computer Vision': 'Preferred knowledge in computer vision technologies', 'Collaboration': 'Experience in team collaboration and business engagement', 'Statistical Modelling': 'Develop advanced statistical and machine learning models', 'SCRUM/Agile': 'Experience working in SCRUM or agile setups', 'Model Maintenance': 'Capability to maintain and monitor machine learning models'} matching_skills={'Machine Learning': 'Experienced in algorithms and machine learning models', 'Python': 'Skilled in Python for software engineering and model development', 'SQL': 'Proficient in SQL for database operations', 'NLP': 'Knowledge in NLP tools and technologies (e.g., Huggingface, FinBert)', 'Collaboration': 'Strong collaboration and team-playing attributes', 'Statistical Modelling': 'Competent in statistical modelling and analysis', 'SCRUM/Agile': 'Familiarity with SCRUM practices and agile development'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "chain = prompt | llm_model | parser\n",
    "\n",
    "structured_llm = chain.invoke(\n",
    "    {\n",
    "        \"job_position\": job_description,\n",
    "        \"my_skills\": skills,\n",
    "    }\n",
    ")\n",
    "print(structured_llm,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The job vacancy at ATP for a 'Data Scientist - Fraud Detection & AI Solutions' primarily focuses on leveraging data science techniques, machine learning, and NLP to detect fraud and optimize processes in the welfare system. Key responsibilities include understanding business requirements, developing machine learning models using Python, monitoring and maintaining these models, and developing and implementing NLP solutions. The job also involves a collaborative working environment in an agile (SCRUM) setup. The candidate's skills largely match the role's requirements, especially in Python, SQL, NLP, Machine Learning, and collaborative working styles. However, the role specifies a preferred background in mathematics, statistics, or related fields and familiarity with 'unsupervised methods and computer vision,' which are not explicitly mentioned among the candidate's current skills. Overall, the candidate is a strong fit for the role, with opportunities to align further through experience or training in unsupervised methods and computer vision.\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_llm.analysis_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'JobAnalysisResult' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstructured_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(structured_llm\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/projects/portofolio/portofolio_env/lib/python3.10/site-packages/pydantic/main.py:856\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'JobAnalysisResult' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "structured_llm.content\n",
    "print(structured_llm.content)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portofolio_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
